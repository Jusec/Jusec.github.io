---
layout:     post
title:      7.机器学习常考内容
subtitle:   机器学习
date:       2022-05-02
author:     Mo
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Machine Learning 
    - DeepLearning  
---

### **1.什么是特征归一化**

数据的标准化（normalization）是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权其中最典型的就是数据的归一化处理，即将数据统一映射到[0,1]区间上。



**特征归一化的作用：数据归一化后，** 更容易正确的收敛到最优解、提升模型的精度，归一化的另一好处是提高精度、深度学习中数据归一化可以防止模型梯度爆炸

### **2.为什么要用1\*1卷积？**

增加网络的深度（加入非线性）、升维或者是降维、跨通道信息交互（channal 的变换）

### **3.padding的作用**

①保持边界信息，如果没有加padding的话，输入图片最边缘的像素点信息只会被卷积核操作一次，但是图像中间的像素点会被扫描到很多遍，那么就会在一定程度上降低边界信息的参考程度，但是在加入padding之后，在实际处理过程中就会从新的边界进行操作，就从一定程度上解决了这个问题。

②可以利用padding对输入尺寸有差异图片进行补齐，使得输入图片尺寸一致。

③在卷积神经网络的卷积层加入Padding，可以使得卷积层的输入维度和输出维度一致。

④卷积神经网络的池化层加入Padding，一般都是保持边界信息和①所述一样。

### **4. pooling如何反向传播**

Max pooling: 下一层的梯度会原封不动地传到上一层最大值所在位置的神经元，其他位置的梯度为0；

Average pooling: 下一层的梯度会平均地分配到上一层的对应相连区块的所有神经元。



**Pooling的作用和缺点：**

增大感受野、平移不变性、降低优化难度和参数。

缺点:造成梯度稀疏，丢失信息



**感受野的理解**：一个卷积核可以映射原始输入图的区域大小。

**感受野的计算公式？**

![image-20220502180731132](https://s2.loli.net/2022/05/02/KZ8JdXU9LD17kyN.png)

其中lk−1为第k−1层对应的感受野大小，fk为第k层的卷积核大小，或者是池化层的池化尺寸大小。

### **5.反向传播的原理：** 

它的主要思想是由后一级的误差计算前一级的误差，从而极大减少运算量。

### **6.各种数据的channel是指什么意思？**

 每个卷积层中卷积核的数量

### **7.卷积层和全连接层的区别**

全连接层的权重矩阵是固定的，即每一次feature map的输入过来必须都得是一定的大小，所以网络最开始的输入图像尺寸必须固定，才能保证传送到全连接层的feature map的大小跟全连接层的权重矩阵匹配。

卷积层就不需要固定大小了，因为它只是对局部区域进行窗口滑动，所以用卷积层取代全连接层成为了可能。

### **8.网络权重初始化**

把w初始化为0、对w随机初始化、Xavier initialization、He initialization

### **9.讲下Attention的原理**

减少处理高维输入数据的计算负担,结构化的选取输入的子集,从而降低数据的维度。让系统更加容易的找到输入的数据中与当前输出信息相关的有用信息,从而提高输出的质量。帮助类似于decoder这样的模型框架更好的学到多种内容模态之间的相互关系。



**Attention有什么缺点**

Attention模块的参数都是通过label和预测值的loss反向传播进行更新，没有引入其他监督信息，因而其受到的监督有局限，容易对label过拟合。

### **10. AuC，RoC，mAP，Recall，Precision，F1-score**

召回率(Recall) = 预测为真实正例 / 所有真实正例样本的个数。



准确率(Precision) =预测为真实正例 / 所有被预测为正例样本的个数。



Precision：P=TP/(TP+FP) 精准率（查准率），Recall：R=TP/(TP+FN) 召回率（查全率 ）



mAP: mean Average Precision, 即各类别AP的平均值，AP: PR曲线下面积，后文会详细讲解，PR曲线: Precision-Recall曲线。



ROC：全称Receiver Operating Characteristic曲线，常用于评价二分类的优劣。



AUC：全称Area Under Curve，被定义为ROC曲线下的面积，取值范围在0.5到1之间。



F1-score：F1值，又称调和平均数，公式(2)和(3)中反应的precision和recall是相互矛盾的，当recall越大时，预测的覆盖率越高，这样precision就会越小，反之亦然，通常，使用F1-score来调和precision和recall。

![image-20220502181226770](https://s2.loli.net/2022/05/02/kBoUP6vat8lfrOb.png)