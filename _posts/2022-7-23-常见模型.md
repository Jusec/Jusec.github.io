---
layout:     post
title:      20. 常见模型
subtitle:   深度学习
date:       2022-07-22
author:     Mo
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Deepling 
---

# BackBone

### 1.MobileNet V1

![image-20220723213558062](https://s2.loli.net/2022/07/23/SKIAwHTBbCsYn9j.png)

![image-20220723213633715](https://s2.loli.net/2022/07/23/R81u4TfWdj3hI5U.png)



#### 理论上普通卷积是深度可分卷积（Depthwise Separable Conv）的计算量的8到9倍

![image-20220723213656987](https://s2.loli.net/2022/07/23/tjIi49sSPlKFOWv.png)







### 2.MoblieNet V2

![image-20220723213953890](https://s2.loli.net/2022/07/23/Ku4saPyI3QlO5hS.png)



![image-20220723214036343](https://s2.loli.net/2022/07/23/PAnY4zC5ruj3i9e.png)



将Relu激活函数换为了ReLU6

![image-20220723214056804](https://s2.loli.net/2022/07/23/RU9LAPT5banwQHZ.png)





### 3.MobileNet V3

![image-20220723214345235](https://s2.loli.net/2022/07/23/2DkOQdEc1Czejox.png)

![image-20220723214418549](https://s2.loli.net/2022/07/23/VfrHRCpv4cU18Dj.png)

![image-20220723214518518](https://s2.loli.net/2022/07/23/8jNoFxCKOp7152G.png)

![image-20220723214532134](https://s2.loli.net/2022/07/23/YgVbRr6AkWJK895.png)



### 4.ShuffleNet V1

![image-20220723214821918](C:/Users/Mo/AppData/Roaming/Typora/typora-user-images/image-20220723214821918.png)

GConv虽然可以减少参数与计算量，但是GConv中不同组之间信息没有交流

由于此提出了channel shuffle

![image-20220710210212278](https://s2.loli.net/2022/07/10/jJCWgXU1Fu3yw8i.png)

![image-20220710210439997](https://s2.loli.net/2022/07/10/FQD8UnRxEwqHeXf.png)





### 5.ShuffleNet V2

![image-20220710212734296](https://s2.loli.net/2022/07/10/ibnvC5fKEpLdhDa.png)







![image-20220712181202073](https://s2.loli.net/2022/07/12/m7ub1hdOiFIGTg4.png)

![image-20220723215400877](https://s2.loli.net/2022/07/23/b6qNkpPVDS2O9tz.png)







### 6.EfficientNet V1

![image-20220714132407744](https://s2.loli.net/2022/07/14/GLzlmYv1KXyeUZF.png)

![image-20220723215613887](https://s2.loli.net/2022/07/23/ubSPMNv2JqrKwtc.png)

![image-20220723215457262](https://s2.loli.net/2022/07/23/2VDfm61MdO9T7gn.png)

![image-20220723215537969](https://s2.loli.net/2022/07/23/f3Vgju4yGASWZcs.png)







### 7.EfficientNet V2

![image-20220723215756258](https://s2.loli.net/2022/07/23/kJHKhGVEgR8Znt1.png)

![image-20220723215724711](https://s2.loli.net/2022/07/23/tQGrajWfUEZXvyL.png)

![image-20220714133230359](https://s2.loli.net/2022/07/14/cNHBurXnpQofigq.png)

 



### 8.Vision Transformer





### 9.Swin Transformer

MSA：FLOPS:
$$
\Omega(M S A)=4 h w C^{2}+2(h w)^{2} C
$$
W-MSA & SW-MSA: FLOPS：
$$
\Omega(W-M S A)=4 h w C^{2}+2 M^{2} h w C=\Omega(S W-M S A)
$$
==W-MSA目的==：减少很大计算量，尤其是在浅层网络

缺点:窗口间无法进行信息交互



==SW-MSA==:进行窗口间的信息交互



==Relative Position Bias==(相对位置偏置):对模型性能有明显提升



![image-20220718115018286](C:/Users/Mo/AppData/Roaming/Typora/typora-user-images/image-20220718115018286.png)

![image-20220718204418302](https://s2.loli.net/2022/07/18/AkmCUuVQeNdgxTq.png)



# Detection

## 1.YOLO系列

### YOLOv4

![image-20220801213910335](https://s2.loli.net/2022/08/01/B5dqKP8XthrNU6W.png)

![image-20220801215400918](https://s2.loli.net/2022/08/01/B67vIDiL3A4lHsw.png) 





### YOLOv5

BackBone：New CSP-Darknet53

Neck:SPPE, New CSP-PAN

Head:YOLOv3 Head

<img src="https://s2.loli.net/2022/08/01/UZhTzpyRtxCFuPw.png" alt="在这里插入图片描述" style="zoom: 200%;" />

Yolov5中用到的数据增强：

Mosaic：将四张图片拼成一张，扩充数据的多样性

Copy paste：将不同图片当中的目标进行复制粘贴到其他图片。（首先数据集必须要有每个目标的实例分割的标签）

Random affine（随机仿射变换）：通过一系列的原子变换的复合来实现，包括：平移（Translation）、缩放（Scale）、旋转（Rotation）和剪切（Shear）

MixUp：将两张图片按一定透明程度混合成一张新图片

Albumentations：滤波、直方图均衡化以及改变图片性质量等等

Augment HSV: 在HSV颜色空间上对图片进行变换，达到数据增量的效果

Random horizontal flip：按水平方向随机翻转





### YOLOX



![image-20220801171847309](https://s2.loli.net/2022/08/01/7w4G2CZDcylWYid.png)



<img src="https://img-blog.csdnimg.cn/08010b4889d5439c9721276e05e5f342.png" alt="在这里插入图片描述" style="zoom: 150%;" />

Yolox的亮点：

1.Anchor-Free

2.decoupled detection head (解耦检测头)

3.advanced label assigning startegy（SimOTA）（更加先进的正负样本匹配策略）



![image-20220801173414217](https://s2.loli.net/2022/08/01/sYZDf98LUgheKFQ.png)



==yolox中head参数是不共享的，yolov5中的head参数是共享的==

![image-20220801173043448](https://s2.loli.net/2022/08/01/gQXSHTb2iBNzmdA.png) 

 ![image-20220801173532123](https://s2.loli.net/2022/08/01/8fn39HgMsDSCpyB.png)

![image-20220801173646641](https://s2.loli.net/2022/08/01/5bUdRyZ8EKHzqo2.png)

SimOTA步骤：

1. 首先计算Anchor Point与GT的cost矩阵
2. 然后计算Anchor Point与GT的IoU矩阵  （每个Anchor Point预测的目标检测框和每个GT之间的IoU）
3. 根据IoU选择前K个Anchor Point （K = min（10，Anchoir Point的个数））
4. 计算每个GT对应的Anchor Point个数（动态计算） （Dynamic k Estimation Strategy）(dynamic_ks = torch.clamp(topk_ious.sum(1).int(),min=1))(其实就是对每一行进行取整求和)
5. 根据上一步得到的dunamic_ks以及cost分配想要的Anchor Point
6. 如果有多个GT同时分配给一个Anchor Point，那么只取cost最小的GT
