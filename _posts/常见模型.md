# ShuffleNet V1

GConv虽然可以减少参数与计算量，但是GConv中不同组之间信息没有交流

由于此提出了channel shuffle

![image-20220710210212278](https://s2.loli.net/2022/07/10/jJCWgXU1Fu3yw8i.png)

![image-20220710210439997](https://s2.loli.net/2022/07/10/FQD8UnRxEwqHeXf.png)





# ShuffleNet V2

![image-20220710212734296](https://s2.loli.net/2022/07/10/ibnvC5fKEpLdhDa.png)







![image-20220712181202073](https://s2.loli.net/2022/07/12/m7ub1hdOiFIGTg4.png)



![image-20220714132407744](https://s2.loli.net/2022/07/14/GLzlmYv1KXyeUZF.png)

![image-20220714133230359](https://s2.loli.net/2022/07/14/cNHBurXnpQofigq.png)

 



# Vision Transformer





# Swin Transformer

MSA：FLOPS:
$$
\Omega(M S A)=4 h w C^{2}+2(h w)^{2} C
$$
W-MSA & SW-MSA: FLOPS：
$$
\Omega(W-M S A)=4 h w C^{2}+2 M^{2} h w C=\Omega(S W-M S A)
$$
==W-MSA目的==：减少很大计算量，尤其是在浅层网络

缺点:窗口间无法进行信息交互



==SW-MSA==:进行窗口间的信息交互



==Relative Position Bias==(相对位置偏置):对模型性能有明显提升



![image-20220718115018286](C:/Users/Mo/AppData/Roaming/Typora/typora-user-images/image-20220718115018286.png)

![image-20220718204418302](https://s2.loli.net/2022/07/18/AkmCUuVQeNdgxTq.png)
